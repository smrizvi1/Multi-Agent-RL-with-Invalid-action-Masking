{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ca3bc-1968-4267-9583-768f9c6a0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from models.system_model import SystemModel\n",
    "from models.dqn import DQN\n",
    "from utils.helpers import create_directory_structure\n",
    "import json\n",
    "\n",
    "# Load configuration\n",
    "config = {\n",
    "    'service_zone_x': 500,\n",
    "    'service_zone_y': 500,\n",
    "    'height_limit': 150,\n",
    "    'num_uavs': 3,\n",
    "    'users_per_cell': 2,\n",
    "    'frequency': 2,  # GHz\n",
    "    'bandwidth': 30,  # kHz\n",
    "    'r_require': 0.15,  # kb\n",
    "    'uav_speed': 5,  # m/s\n",
    "    'power_unit': 100 * 10000,  # 20mW\n",
    "    'noise_power': 10**(-9) * 10000,\n",
    "    'episodes': 300,\n",
    "    'time_steps': 120,\n",
    "    'clustering_interval': 40,\n",
    "    'epsilon_start': 0.9,\n",
    "    'epsilon_end': 0.05,\n",
    "    'epsilon_decay': 200,\n",
    "    'gamma': 0.99,\n",
    "    'batch_size': 128\n",
    "}\n",
    "\n",
    "def train():\n",
    "    \"\"\"Main training loop\"\"\"\n",
    "    # Create necessary directories\n",
    "    create_directory_structure()\n",
    "    \n",
    "    # Initialize environment and agent\n",
    "    env = SystemModel(config)\n",
    "    state_dim = env.num_uavs * 3 + env.num_users\n",
    "    agent = DQN(state_dim=state_dim, \n",
    "                num_uavs=env.num_uavs, \n",
    "                num_users=env.num_users)\n",
    "    \n",
    "    # Training metrics\n",
    "    episode_rewards = []\n",
    "    throughput_history = []\n",
    "    worst_user_rates = []\n",
    "    \n",
    "    # Training loop\n",
    "    for episode in range(config['episodes']):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        epsilon = max(\n",
    "            config['epsilon_end'],\n",
    "            config['epsilon_start'] - episode / config['epsilon_decay']\n",
    "        )\n",
    "        \n",
    "        for t in range(config['time_steps']):\n",
    "            # Periodic user clustering\n",
    "            if t % config['clustering_interval'] == 0:\n",
    "                user_association = agent.cluster_users(env.uav_positions, env.user_positions)\n",
    "            \n",
    "            # UAV actions\n",
    "            for uav_idx in range(env.num_uavs):\n",
    "                # Get cluster size for current UAV\n",
    "                cluster_size = len(np.where(user_association.iloc[0,:] == uav_idx)[0])\n",
    "                \n",
    "                # Choose and take action\n",
    "                action = agent.choose_action(state, epsilon, uav_idx, user_association)\n",
    "                power_allocation = agent.get_power_allocation(action, cluster_size)\n",
    "                env.take_action(action, uav_idx, power_allocation)\n",
    "                \n",
    "                # Calculate reward\n",
    "                sinr = env.calculate_sinr(user_association)\n",
    "                rates, sum_rate, worst_rate = env.calculate_rates(sinr)\n",
    "                \n",
    "                # Apply penalty if QoS requirement not met\n",
    "                reward = sum_rate\n",
    "                if worst_rate < config['r_require']:\n",
    "                    reward *= 0.5\n",
    "                \n",
    "                # Get next state and store experience\n",
    "                next_state = env.get_state(uav_idx)\n",
    "                agent.remember(state, action, next_state, reward, uav_idx, cluster_size)\n",
    "                \n",
    "                # Train agent\n",
    "                agent.train(gamma=config['gamma'])\n",
    "                \n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "            \n",
    "            # Update metrics\n",
    "            if t == config['time_steps'] - 1:\n",
    "                throughput_history.append(sum_rate)\n",
    "                worst_user_rates.append(worst_rate)\n",
    "        \n",
    "        episode_rewards.append(episode_reward)\n",
    "        \n",
    "        # Print progress\n",
    "        if (episode + 1) % 10 == 0:\n",
    "            print(f\"Episode {episode + 1}/{config['episodes']}\")\n",
    "            print(f\"Average Reward: {episode_reward/config['time_steps']:.2f}\")\n",
    "            print(f\"Throughput: {sum_rate:.2f}\")\n",
    "            print(f\"Worst User Rate: {worst_rate:.2f}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    # Save results\n",
    "    save_results(episode_rewards, throughput_history, worst_user_rates)\n",
    "\n",
    "def save_results(episode_rewards, throughput_history, worst_user_rates):\n",
    "    \"\"\"Save training results and generate plots\"\"\"\n",
    "    # Save metrics\n",
    "    np.save(\"results/episode_rewards.npy\", episode_rewards)\n",
    "    np.save(\"results/throughput_history.npy\", throughput_history)\n",
    "    np.save(\"results/worst_user_rates.npy\", worst_user_rates)\n",
    "\n",
    "    # Plot episode rewards\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(episode_rewards)\n",
    "    plt.title('Episode Rewards over Time')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('results/episode_rewards.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot throughput history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(throughput_history)\n",
    "    plt.title('System Throughput over Episodes')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Throughput (kb/s)')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('results/throughput.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot worst user rates\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(worst_user_rates)\n",
    "    plt.title('Worst User Rate over Episodes')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Rate (kb/s)')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('results/worst_user_rates.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Save configuration\n",
    "    with open('results/config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "\n",
    "def evaluate(model_path=\"results/final_model.h5\"):\n",
    "    \"\"\"Evaluate trained model performance\"\"\"\n",
    "    env = SystemModel(config)\n",
    "    state_dim = env.num_uavs * 3 + env.num_users\n",
    "    agent = DQN(state_dim=state_dim, \n",
    "                num_uavs=env.num_uavs, \n",
    "                num_users=env.num_users)\n",
    "    \n",
    "    # Load trained model weights\n",
    "    agent.model.load_weights(model_path)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    throughputs = []\n",
    "    worst_rates = []\n",
    "    trajectories = []\n",
    "    \n",
    "    # Run evaluation episodes\n",
    "    for episode in range(5):  # Run 5 evaluation episodes\n",
    "        state = env.reset()\n",
    "        episode_trajectory = []\n",
    "        \n",
    "        for t in range(config['time_steps']):\n",
    "            if t % config['clustering_interval'] == 0:\n",
    "                user_association = agent.cluster_users(env.uav_positions, env.user_positions)\n",
    "            \n",
    "            episode_trajectory.append({\n",
    "                'uav_positions': env.uav_positions.copy(),\n",
    "                'user_positions': env.user_positions.copy()\n",
    "            })\n",
    "            \n",
    "            for uav_idx in range(env.num_uavs):\n",
    "                cluster_size = len(np.where(user_association.iloc[0,:] == uav_idx)[0])\n",
    "                \n",
    "                # Choose best action (no exploration)\n",
    "                action = agent.choose_action(state, epsilon=0, uav_idx=uav_idx,\n",
    "                                          user_association=user_association)\n",
    "                power_allocation = agent.get_power_allocation(action, cluster_size)\n",
    "                env.take_action(action, uav_idx, power_allocation)\n",
    "                \n",
    "                sinr = env.calculate_sinr(user_association)\n",
    "                rates, sum_rate, worst_rate = env.calculate_rates(sinr)\n",
    "                state = env.get_state(uav_idx)\n",
    "            \n",
    "            if t == config['time_steps'] - 1:\n",
    "                throughputs.append(sum_rate)\n",
    "                worst_rates.append(worst_rate)\n",
    "        \n",
    "        trajectories.append(episode_trajectory)\n",
    "    \n",
    "    # Save evaluation results\n",
    "    np.save(\"results/eval_throughputs.npy\", throughputs)\n",
    "    np.save(\"results/eval_worst_rates.npy\", worst_rates)\n",
    "    np.save(\"results/eval_trajectories.npy\", trajectories)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"Average Throughput: {np.mean(throughputs):.2f} ± {np.std(throughputs):.2f}\")\n",
    "    print(f\"Average Worst User Rate: {np.mean(worst_rates):.2f} ± {np.std(worst_rates):.2f}\")\n",
    "    \n",
    "    # Plot example trajectory\n",
    "    plot_trajectory(trajectories[0])\n",
    "\n",
    "def plot_trajectory(trajectory):\n",
    "    \"\"\"Plot UAV and user trajectories for visualization\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot UAV trajectories\n",
    "    for uav_idx in range(config['num_uavs']):\n",
    "        uav_x = [step['uav_positions'].iloc[0, uav_idx] for step in trajectory]\n",
    "        uav_y = [step['uav_positions'].iloc[1, uav_idx] for step in trajectory]\n",
    "        uav_z = [step['uav_positions'].iloc[2, uav_idx] for step in trajectory]\n",
    "        \n",
    "        plt.plot(uav_x, uav_y, 'b-', alpha=0.5, label=f'UAV {uav_idx+1}' if uav_idx==0 else \"\")\n",
    "        plt.plot(uav_x[0], uav_y[0], 'b^', label='UAV Start' if uav_idx==0 else \"\")\n",
    "        plt.plot(uav_x[-1], uav_y[-1], 'bs', label='UAV End' if uav_idx==0 else \"\")\n",
    "    \n",
    "    # Plot user positions\n",
    "    for user_idx in range(config['num_uavs'] * config['users_per_cell']):\n",
    "        user_x = [step['user_positions'].iloc[0, user_idx] for step in trajectory]\n",
    "        user_y = [step['user_positions'].iloc[1, user_idx] for step in trajectory]\n",
    "        \n",
    "        plt.plot(user_x, user_y, 'r:', alpha=0.3, label='User Path' if user_idx==0 else \"\")\n",
    "        plt.plot(user_x[0], user_y[0], 'r^', label='User Start' if user_idx==0 else \"\")\n",
    "        plt.plot(user_x[-1], user_y[-1], 'rs', label='User End' if user_idx==0 else \"\")\n",
    "    \n",
    "    plt.title('UAV and User Trajectories')\n",
    "    plt.xlabel('X Position (m)')\n",
    "    plt.ylabel('Y Position (m)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig('results/trajectory.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Train the model\n",
    "    train()\n",
    "    \n",
    "    # Evaluate the trained model\n",
    "    evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
