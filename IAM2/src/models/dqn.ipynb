{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4740e6-c2cd-4ae4-8bac-3b6281286bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from .action_masking import ActionMasking\n",
    "from ..config.parameters import *\n",
    "\n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        self.update_freq = 2000  # Model update frequency\n",
    "        self.replay_size = 20000  # Training set size \n",
    "        self.step = 0\n",
    "        self.replay_queue = deque(maxlen=self.replay_size)\n",
    "        \n",
    "        # Define state and action dimensions\n",
    "        self.state_dim = NumberOfUAVs*3 + NumberOfUsers\n",
    "        self.action_dim = 126  # Total actions\n",
    "        \n",
    "        # Initialize action masking\n",
    "        self.action_masker = ActionMasking()\n",
    "        \n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"Create neural network with integrated action masking\"\"\"\n",
    "        state_input = Input(shape=(self.state_dim,))\n",
    "        mask_input = Input(shape=(self.action_dim,))\n",
    "        \n",
    "        # Hidden layers\n",
    "        x = Dense(90, activation='relu')(state_input)\n",
    "        x = Dense(90, activation='relu')(x)\n",
    "        \n",
    "        # Q-value output before masking\n",
    "        q_values = Dense(self.action_dim)(x)\n",
    "        \n",
    "        # Apply mask using element-wise multiplication\n",
    "        masked_q_values = self.action_masker.masking_layer([q_values, mask_input])\n",
    "        \n",
    "        model = Model(inputs=[state_input, mask_input], outputs=masked_q_values)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def Choose_action(self, s, epsilon, acting_UAV, User_asso_list):\n",
    "        \"\"\"Choose action with integrated masking\"\"\"\n",
    "        # Get cluster size and action mask\n",
    "        acting_user_list = np.where(User_asso_list.iloc[0,:] == acting_UAV)[0]\n",
    "        cluster_size = len(acting_user_list)\n",
    "        action_mask = self.action_masker.get_mask(cluster_size)\n",
    "        \n",
    "        if np.random.uniform() < epsilon:\n",
    "            # Random action from valid actions only\n",
    "            valid_actions = np.where(action_mask > 0)[0]\n",
    "            return np.random.choice(valid_actions)\n",
    "        else:\n",
    "            # Get Q-values with masking\n",
    "            state = np.expand_dims(s, axis=0)\n",
    "            mask = np.expand_dims(action_mask, axis=0)\n",
    "            q_values = self.model.predict([state, mask], verbose=0)[0]\n",
    "            return np.argmax(q_values)\n",
    "\n",
    "    def remember(self, s, a, next_s, reward, acting_UAV, User_asso_list):\n",
    "        \"\"\"Store experience with action mask\"\"\"\n",
    "        cluster_size = len(np.where(User_asso_list.iloc[0,:] == acting_UAV)[0])\n",
    "        mask = self.action_masker.get_mask(cluster_size)\n",
    "        self.replay_queue.append((s, a, next_s, reward, mask))\n",
    "\n",
    "    def train(self, batch_size=128, lr=1, factor=1):\n",
    "        \"\"\"Train with action masking\"\"\"\n",
    "        if len(self.replay_queue) < self.replay_size:\n",
    "            return\n",
    "        self.step += 1\n",
    "        \n",
    "        if self.step % self.update_freq == 0:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        # Sample batch\n",
    "        replay_batch = random.sample(self.replay_queue, batch_size)\n",
    "        states = np.array([replay[0] for replay in replay_batch])\n",
    "        actions = np.array([replay[1] for replay in replay_batch])\n",
    "        next_states = np.array([replay[2] for replay in replay_batch])\n",
    "        rewards = np.array([replay[3] for replay in replay_batch])\n",
    "        masks = np.array([replay[4] for replay in replay_batch])\n",
    "        \n",
    "        # Get current Q values\n",
    "        current_q = self.model.predict([states, masks], verbose=0)\n",
    "        \n",
    "        # Get next Q values from target model\n",
    "        next_q = self.target_model.predict([next_states, masks], verbose=0)\n",
    "        \n",
    "        # Update Q values\n",
    "        for i in range(batch_size):\n",
    "            current_q[i][actions[i]] = (1 - lr) * current_q[i][actions[i]] + \\\n",
    "                                     lr * (rewards[i] + factor * np.max(next_q[i]))\n",
    "        \n",
    "        # Train the model\n",
    "        self.model.fit([states, masks], current_q, verbose=0)\n",
    "\n",
    "    def User_association(self, UAV_Position, User_Position, UAVsnumber, Usersnumber):\n",
    "        User_Position_array = np.zeros([Usersnumber, 2])\n",
    "        User_Position_array[:, 0] = User_Position.iloc[0,:].T\n",
    "        User_Position_array[:, 1] = User_Position.iloc[1,:].T\n",
    "\n",
    "        K_means_association = KMeans(n_clusters=UAVsnumber).fit(User_Position_array)\n",
    "        User_cluster = K_means_association.labels_\n",
    "        Cluster_center = K_means_association.cluster_centers_\n",
    "\n",
    "        # Select nearest UAV to serve\n",
    "        UAV_Position_array = np.zeros([UAVsnumber, 2])\n",
    "        UAV_Position_array[:, 0] = UAV_Position.iloc[0, :].T\n",
    "        UAV_Position_array[:, 1] = UAV_Position.iloc[1, :].T\n",
    "\n",
    "        User_association_list = pd.DataFrame(\n",
    "            np.zeros((1, Usersnumber)),\n",
    "            columns=np.arange(Usersnumber).tolist(),\n",
    "        )\n",
    "\n",
    "        # New SSD cluster UAV pairing\n",
    "        distance_UAVi2C = np.zeros((NumberOfUAVs, NumberOfUAVs))\n",
    "        for UAV_name in range(NumberOfUAVs):\n",
    "            for cluster_name in range(NumberOfUAVs):\n",
    "                distance_UAVi2C[UAV_name,cluster_name] = np.linalg.norm(UAV_Position_array[UAV_name,:]-Cluster_center[cluster_name])\n",
    "\n",
    "        row_ind, col_ind = linear_sum_assignment(distance_UAVi2C)\n",
    "        \n",
    "        for i in range(NumberOfUAVs):\n",
    "            Servied_cluster = col_ind[i]\n",
    "            Servied_cluster_list = Servied_cluster\n",
    "            Servied_users = np.where(User_cluster==Servied_cluster_list)\n",
    "            Servied_users_list = Servied_users[0]\n",
    "\n",
    "            for j in range(np.size(Servied_users)):\n",
    "                User_association_list.iloc[0,Servied_users_list[j]] = int(i)\n",
    "            User_association_list = User_association_list.astype('int')\n",
    "\n",
    "        return User_association_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
